import { spawn } from 'child_process';
import * as vscode from 'vscode';

export async function fetchAIResponse(
    prompt: string,
    filePath: string | null,
    model: string,
    context: vscode.ExtensionContext,
    callback: (chunk: string, isFinal: boolean) => void
) {
    const isLocal = isLocalModel(model);

    if (isLocal) {
        runOllamaModel(model, prompt, filePath, callback);
    } else {
        const apiKey = await getApiKeyForModel(model, context);
        if (!apiKey) {
            callback(`❌ API key for ${model} not found. Please save it in the UI.`, true);
            return;
        }

        runCloudModel(model, prompt, apiKey, filePath, callback);
    }
}

export async function analyzeCode(
    filePath: string,
    model: string,
    context: vscode.ExtensionContext,
    callback: (chunk: string, isFinal: boolean) => void
) {
    const isLocal = isLocalModel(model);

    try {
        const fileContent = await vscode.workspace.fs.readFile(vscode.Uri.file(filePath));
        const code = new TextDecoder().decode(fileContent);
        const analysisPrompt = `Analyze the following code and provide suggestions for improvements, optimizations, and best practices:\n\n${code}`;

        if (isLocal) {
            runOllamaModel(model, analysisPrompt, null, callback);
        } else {
            const apiKey = await getApiKeyForModel(model, context);
            if (!apiKey) {
                callback(`❌ API key for ${model} not found. Please save it in the UI.`, true);
                return;
            }

            runCloudModel(model, analysisPrompt, apiKey, filePath, callback);
        }
    } catch (error: any) {
        callback(`❌ Error reading file: ${error.message}\n\n`, true);
    }
}

// --- Local Ollama execution ---
function runOllamaModel(
    model: string,
    prompt: string,
    filePath: string | null,
    callback: (chunk: string, isFinal: boolean) => void
) {
    const process = spawn("ollama", ["run", model, prompt], { stdio: ['ignore', 'pipe', 'pipe'] });

    let fullResponse = "";

    process.stdout.on("data", (data) => {
        const chunk = data.toString();
        fullResponse += chunk;
        callback(chunk, false);
    });

    process.on("close", async (code) => {
        console.log(`✅ Ollama process exited with code ${code}`);

        const extractedCode = extractCode(fullResponse);

        if (filePath && extractedCode) {
            try {
                await vscode.workspace.fs.writeFile(vscode.Uri.file(filePath), Buffer.from(extractedCode, 'utf-8'));
                callback(`✅ Code written to ${filePath}!\n\n`, true);
            } catch (err: any) {
                callback(`❌ Error writing file: ${err.message}\n\n`, true);
            }
        } else {
            callback("\n\n" + formatText(fullResponse) + `\n\nMessage generated by ${model}.`, true);
        }
    });
}

// --- Cloud model execution ---
async function runCloudModel(
    model: string,
    prompt: string,
    apiKey: string,
    filePath: string | null,
    callback: (chunk: string, isFinal: boolean) => void
) {
    let endpoint = "";
    let body: any = {};
    let headers: any = {};

    // Cloud model-specific setup
    switch (model) {
        case "gemini":
            endpoint = `https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?key=${apiKey}`;
            body = { contents: [{ parts: [{ text: prompt }] }] };
            headers = { "Content-Type": "application/json" };
            break;

        case "gpt-4o":
            endpoint = "https://api.openai.com/v1/chat/completions";
            body = {
                model: "gpt-4o",
                messages: [{ role: "user", content: prompt }],
                temperature: 0.7,
                stream: false
            };
            headers = {
                "Authorization": `Bearer ${apiKey}`,
                "Content-Type": "application/json"
            };
            break;

        case "mistral":
            endpoint = "https://api.mistral.ai/v1/chat/completions";
            body = {
                model: "mistral-medium",
                messages: [{ role: "user", content: prompt }],
                temperature: 0.7,
                stream: false
            };
            headers = {
                "Authorization": `Bearer ${apiKey}`,
                "Content-Type": "application/json"
            };
            break;

        default:
            callback(`❌ Unsupported cloud model: ${model}`, true);
            return;
    }

    try {
        const response = await fetch(endpoint, {
            method: "POST",
            headers,
            body: JSON.stringify(body),
        });

        const data: any = await response.json();
        let reply = model === "gemini"
            ? data?.candidates?.[0]?.content?.parts?.[0]?.text || "⚠️ No response."
            : data?.choices?.[0]?.message?.content || "⚠️ No response.";

        const extractedCode = extractCode(reply);

        if (filePath && extractedCode) {
            try {
                await vscode.workspace.fs.writeFile(vscode.Uri.file(filePath), Buffer.from(extractedCode, 'utf-8'));
                callback("\n\n" + formatText(reply) + `\n\nMessage generated by ${model}.`, true);
                callback(`✅ Code written to ${filePath}!\n\n`, true);
            } catch (err: any) {
                callback(`❌ Error writing file: ${err.message}\n\n`, true);
            }
        }

    } catch (err: any) {
        callback(`❌ Error calling ${model}: ${err.message}`, true);
    }
}

// --- Helpers ---
function isLocalModel(model: string): boolean {
    const localModels = ["llama3.1", "llama3.2", "gemma", "deepseek-r1"];
    return localModels.includes(model);
}

async function getApiKeyForModel(model: string, context: vscode.ExtensionContext): Promise<string | null> {
    return await context.secrets.get(`${model}_apiKey`) ?? null;
}

function extractCode(text: string): string {
    const codeRegex = /```(?:\w+\n)?([\s\S]*?)```/g;
    let match;
    let codeBlocks = [];

    while ((match = codeRegex.exec(text)) !== null) {
        codeBlocks.push(match[1].trim());
    }

    return codeBlocks.length > 0 ? codeBlocks.join("\n\n") : text;
}

function formatText(text: string): string {
    return text
        .replace(/\n/g, "<br>")
        .replace(/```([\s\S]*?)```/g, '<pre><code>$1</code></pre>');
}
